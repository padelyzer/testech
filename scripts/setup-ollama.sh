#!/bin/bash

echo "ğŸ¤– Configurando Ollama para anÃ¡lisis de imÃ¡genes gratuito..."

# Detectar sistema operativo
if [[ "$OSTYPE" == "darwin"* ]]; then
    # macOS
    if ! command -v ollama &> /dev/null; then
        echo "ğŸ“¥ Instalando Ollama en macOS..."
        curl -fsSL https://ollama.ai/install.sh | sh
    else
        echo "âœ… Ollama ya estÃ¡ instalado"
    fi
elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
    # Linux
    if ! command -v ollama &> /dev/null; then
        echo "ğŸ“¥ Instalando Ollama en Linux..."
        curl -fsSL https://ollama.ai/install.sh | sh
    else
        echo "âœ… Ollama ya estÃ¡ instalado"
    fi
else
    echo "âš ï¸  Sistema operativo no soportado automÃ¡ticamente"
    echo "Por favor instala Ollama manualmente desde: https://ollama.ai"
    exit 1
fi

# Iniciar servicio de Ollama
echo "ğŸš€ Iniciando servicio Ollama..."
ollama serve &

# Esperar a que el servicio inicie
sleep 5

# Descargar modelo de visiÃ³n (LLaVA)
echo "ğŸ“¦ Descargando modelo LLaVA para anÃ¡lisis de imÃ¡genes..."
ollama pull llava:latest

# Descargar modelo de texto (opcional)
echo "ğŸ“¦ Descargando modelo de texto Llama..."
ollama pull llama3.2:latest

echo ""
echo "âœ… Â¡ConfiguraciÃ³n completada!"
echo ""
echo "ğŸ¯ Ollama estÃ¡ ejecutÃ¡ndose en: http://localhost:11434"
echo "ğŸ” Modelos disponibles:"
ollama list

echo ""
echo "ğŸ’¡ Para usar el sistema ahora:"
echo "   node agents/cli.js analyze <url>"
echo "   node agents/cli.js clone <url>"